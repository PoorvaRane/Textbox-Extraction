{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The architecture of our CNN is given in Figure 1. The structure\n",
    "# can be summarized as 28×28×1−26×26×4−100−M,\n",
    "# where M is the number of classes. The input is a grayscale\n",
    "# image patch. The size of the image patch is 28×28 pixels. Our\n",
    "# CNN architecture contains only one convolution layer which\n",
    "# consists of 4 kernels. The size of each kernel is 3 × 3 pixels.\n",
    "# Unlike other traditional CNN architecture, the pooling layer is\n",
    "# not used in our architecture. Then one fully connected layer\n",
    "# of 100 neurons follows the convolution layer. The last layer\n",
    "# consists of a logistic regression with softmax which outputs\n",
    "# the probability of each class, such that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get train data\n",
    "'''\n",
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_data = training_data[:2000] #Test on first 2000 image segments\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self): # DO NOT HARDCODE\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel 10x10, 4 output channels, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(4 * 8 * 8, 100)\n",
    "        self.fc2 = nn.Linear(100, 2) #Number of classes = 'text'\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear (256 -> 100)\n",
      "  (fc2): Linear (100 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([4, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Total number of learnable parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "trainloader = DataLoader(training_data.tolist(), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.648\n",
      "[1,   400] loss: 0.963\n",
      "[1,   600] loss: 0.913\n",
      "[1,   800] loss: 0.313\n",
      "[1,  1000] loss: 0.313\n",
      "[1,  1200] loss: 1.108\n",
      "[1,  1400] loss: 1.068\n",
      "[1,  1600] loss: 0.388\n",
      "[1,  1800] loss: 0.313\n",
      "[1,  2000] loss: 0.548\n",
      "[2,   200] loss: 0.648\n",
      "[2,   400] loss: 0.963\n",
      "[2,   600] loss: 0.913\n",
      "[2,   800] loss: 0.313\n",
      "[2,  1000] loss: 0.313\n",
      "[2,  1200] loss: 1.108\n",
      "[2,  1400] loss: 1.068\n",
      "[2,  1600] loss: 0.388\n",
      "[2,  1800] loss: 0.313\n",
      "[2,  2000] loss: 0.548\n"
     ]
    }
   ],
   "source": [
    "# Training Phase\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.unsqueeze(1).float()), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4865  0.5135\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input to CNN is 10x10\n",
    "\n",
    "input = Variable(torch.randn(1, 1, 10, 10)) # Here random input is given\n",
    "out = net(input)\n",
    "print(out)\n",
    "# output size is 1x2 because there are 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DUMMY CODE\n",
    "# out = net(input)\n",
    "target = Variable(torch.arange(0, 2))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "N = len(X_Train)\n",
    "H = X_Train[0].shape[0]\n",
    "W = X_Train[0].shape[1]\n",
    "trainTensor = torch.LongTensor(N, H, W)\n",
    "for i in range(N):\n",
    "    trainTensor[i] = torch.LongTensor(X_Train[i].tolist())\n",
    "trainTensor = trainTensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109, 106, 105, 100,  98,  98,  98,  94,  95,  90],\n",
       "       [ 38,  48,  44,  32,  38,  35,  36,  29,  33,  29],\n",
       "       [ 24,  22,  24,  24,  21,  22,  22,  20,  19,  21],\n",
       "       [  8,   8,   7,   8,  10,  10,   8,   8,   9,   8],\n",
       "       [ 23,  21,  21,   8,  19,   3,  24,  30,  26,  22],\n",
       "       [  7,   7,   5,   4,   7,   9,   8,   7,   6,   7],\n",
       "       [  1,   0,   0,   0,   1,   7,   2,   2,   3,   1],\n",
       "       [ 13,   7,   3,   4,   2,   7,  11,   4,   9,   9],\n",
       "       [ 18,  23,  36,  18,  28,  28,  37,  47,  39,  50],\n",
       "       [ 24,  35,  31,  51,  10,  55,  66,  77,  67,  61]], dtype=uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  109  106  105  100   98   98   98   94   95   90\n",
       "   38   48   44   32   38   35   36   29   33   29\n",
       "   24   22   24   24   21   22   22   20   19   21\n",
       "    8    8    7    8   10   10    8    8    9    8\n",
       "   23   21   21    8   19    3   24   30   26   22\n",
       "    7    7    5    4    7    9    8    7    6    7\n",
       "    1    0    0    0    1    7    2    2    3    1\n",
       "   13    7    3    4    2    7   11    4    9    9\n",
       "   18   23   36   18   28   28   37   47   39   50\n",
       "   24   35   31   51   10   55   66   77   67   61\n",
       "[torch.ByteTensor of size 1x10x10]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
