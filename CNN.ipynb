{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The architecture of our CNN is given in Figure 1. The structure\n",
    "# can be summarized as 10×10x1−26×26×4−100−M,\n",
    "# where M is the number of classes. The input is a grayscale\n",
    "# image patch. The size of the image patch is 28×28 pixels. Our\n",
    "# CNN architecture contains only one convolution layer which\n",
    "# consists of 4 kernels. The size of each kernel is 3 × 3 pixels.\n",
    "# Unlike other traditional CNN architecture, the pooling layer is\n",
    "# not used in our architecture. Then one fully connected layer\n",
    "# of 100 neurons follows the convolution layer. The last layer\n",
    "# consists of a logistic regression with softmax which outputs\n",
    "# the probability of each class, such that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21643, 2)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get train data\n",
    "'''\n",
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_data = training_data #Test on first 2000 image segments\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1810, 2)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get Validation data\n",
    "'''\n",
    "validation_data = pickle.load(open('validation_data.pkl','r'))\n",
    "\n",
    "validation_data = np.array(validation_data)\n",
    "validation_data = validation_data \n",
    "\n",
    "X_Train = validation_data[:,0]\n",
    "y_Train = validation_data[:,1]\n",
    "\n",
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self): # DO NOT HARDCODE\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel 10x10, 4 output channels, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(4 * 8 * 8, 100)\n",
    "        self.fc2 = nn.Linear(100, 2) #Number of classes = 'text'\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #         dropout with 0.5\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #out = self.sigmoid(x)\n",
    "#         x = F.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout): Dropout (p = 0.5)\n",
      "  (fc1): Linear (256 -> 100)\n",
      "  (fc2): Linear (100 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([4, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Total number of learnable parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "trainloader = DataLoader(training_data.tolist(), batch_size=1, shuffle=True)\n",
    "validloader = DataLoader(training_data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_function(trainloader, net, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.unsqueeze(0).float()), Variable(labels.long())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_function(validloader, net, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels_var = Variable(inputs.unsqueeze(0).float(), volatile=True), Variable(labels.long(), volatile=True)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels_var)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "#         if i % 200 == 199:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 200))\n",
    "#             running_loss = 0.0\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print ('predicted: %d' % (predicted))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the network on the 1810 test images: %d %%' % (100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.658\n",
      "[1,   400] loss: 0.743\n",
      "[1,   600] loss: 0.729\n",
      "[1,   800] loss: 0.567\n",
      "[1,  1000] loss: 0.567\n",
      "[1,  1200] loss: 0.782\n",
      "[1,  1400] loss: 0.771\n",
      "[1,  1600] loss: 0.588\n",
      "[1,  1800] loss: 0.567\n",
      "[1,  2000] loss: 0.631\n",
      "[1,  2200] loss: 0.740\n",
      "[1,  2400] loss: 0.757\n",
      "[1,  2600] loss: 0.567\n",
      "[1,  2800] loss: 0.567\n",
      "[1,  3000] loss: 0.752\n",
      "[1,  3200] loss: 0.775\n",
      "[1,  3400] loss: 0.656\n",
      "[1,  3600] loss: 0.567\n",
      "[1,  3800] loss: 0.641\n",
      "[1,  4000] loss: 0.760\n",
      "[1,  4200] loss: 0.749\n",
      "[1,  4400] loss: 0.569\n",
      "[1,  4600] loss: 0.567\n",
      "[1,  4800] loss: 0.759\n",
      "[1,  5000] loss: 0.792\n",
      "[1,  5200] loss: 0.656\n",
      "[1,  5400] loss: 0.567\n",
      "[1,  5600] loss: 0.729\n",
      "[1,  5800] loss: 0.766\n",
      "[1,  6000] loss: 0.658\n",
      "[1,  6200] loss: 0.567\n",
      "[1,  6400] loss: 0.567\n",
      "[1,  6600] loss: 0.778\n",
      "[1,  6800] loss: 0.764\n",
      "[1,  7000] loss: 0.627\n",
      "[1,  7200] loss: 0.567\n",
      "[1,  7400] loss: 0.657\n",
      "[1,  7600] loss: 0.774\n",
      "[1,  7800] loss: 0.739\n",
      "[1,  8000] loss: 0.567\n",
      "[1,  8200] loss: 0.588\n",
      "[1,  8400] loss: 0.778\n",
      "[1,  8600] loss: 0.782\n",
      "[1,  8800] loss: 0.597\n",
      "[1,  9000] loss: 0.567\n",
      "[1,  9200] loss: 0.658\n",
      "[1,  9400] loss: 0.774\n",
      "[1,  9600] loss: 0.717\n",
      "[1,  9800] loss: 0.567\n",
      "[1, 10000] loss: 0.528\n",
      "[1, 10200] loss: 0.780\n",
      "[1, 10400] loss: 0.774\n",
      "[1, 10600] loss: 0.611\n",
      "[1, 10800] loss: 0.567\n",
      "[1, 11000] loss: 0.661\n",
      "[1, 11200] loss: 0.756\n",
      "[1, 11400] loss: 0.705\n",
      "[1, 11600] loss: 0.567\n",
      "[1, 11800] loss: 0.556\n",
      "[1, 12000] loss: 0.786\n",
      "[1, 12200] loss: 0.776\n",
      "[1, 12400] loss: 0.609\n",
      "[1, 12600] loss: 0.567\n",
      "[1, 12800] loss: 0.656\n",
      "[1, 13000] loss: 0.768\n",
      "[1, 13200] loss: 0.735\n",
      "[1, 13400] loss: 0.567\n",
      "[1, 13600] loss: 0.567\n",
      "[1, 13800] loss: 0.778\n",
      "[1, 14000] loss: 0.806\n",
      "[1, 14200] loss: 0.646\n",
      "[1, 14400] loss: 0.567\n",
      "[1, 14600] loss: 0.664\n",
      "[1, 14800] loss: 0.766\n",
      "[1, 15000] loss: 0.735\n",
      "[1, 15200] loss: 0.567\n",
      "[1, 15400] loss: 0.565\n",
      "[1, 15600] loss: 0.778\n",
      "[1, 15800] loss: 0.770\n",
      "[1, 16000] loss: 0.638\n",
      "[1, 16200] loss: 0.567\n",
      "[1, 16400] loss: 0.612\n",
      "[1, 16600] loss: 0.749\n",
      "[1, 16800] loss: 0.751\n",
      "[1, 17000] loss: 0.567\n",
      "[1, 17200] loss: 0.553\n",
      "[1, 17400] loss: 0.764\n",
      "[1, 17600] loss: 0.798\n",
      "[1, 17800] loss: 0.650\n",
      "[1, 18000] loss: 0.567\n",
      "[1, 18200] loss: 0.642\n",
      "[1, 18400] loss: 0.779\n",
      "[1, 18600] loss: 0.751\n",
      "[1, 18800] loss: 0.567\n",
      "[1, 19000] loss: 0.608\n",
      "[1, 19200] loss: 0.763\n",
      "[1, 19400] loss: 0.805\n",
      "[1, 19600] loss: 0.588\n",
      "[1, 19800] loss: 0.567\n",
      "[1, 20000] loss: 0.623\n",
      "[1, 20200] loss: 0.763\n",
      "[1, 20400] loss: 0.763\n",
      "[1, 20600] loss: 0.570\n",
      "[1, 20800] loss: 0.559\n",
      "[1, 21000] loss: 0.666\n",
      "[1, 21200] loss: 0.585\n",
      "[1, 21400] loss: 0.567\n",
      "[1, 21600] loss: 0.567\n",
      "Accuracy of the network on the 1810 test images: 62 %\n",
      "[2,   200] loss: 0.638\n",
      "[2,   400] loss: 0.838\n",
      "[2,   600] loss: 0.807\n",
      "[2,   800] loss: 0.425\n",
      "[2,  1000] loss: 0.425\n",
      "[2,  1200] loss: 0.931\n",
      "[2,  1400] loss: 0.905\n",
      "[2,  1600] loss: 0.472\n",
      "[2,  1800] loss: 0.425\n",
      "[2,  2000] loss: 0.574\n",
      "[2,  2200] loss: 0.832\n",
      "[2,  2400] loss: 0.873\n",
      "[2,  2600] loss: 0.425\n",
      "[2,  2800] loss: 0.425\n",
      "[2,  3000] loss: 0.861\n",
      "[2,  3200] loss: 0.915\n",
      "[2,  3400] loss: 0.635\n",
      "[2,  3600] loss: 0.425\n",
      "[2,  3800] loss: 0.604\n",
      "[2,  4000] loss: 0.880\n",
      "[2,  4200] loss: 0.854\n",
      "[2,  4400] loss: 0.428\n",
      "[2,  4600] loss: 0.425\n",
      "[2,  4800] loss: 0.877\n",
      "[2,  5000] loss: 0.956\n",
      "[2,  5200] loss: 0.635\n",
      "[2,  5400] loss: 0.425\n",
      "[2,  5600] loss: 0.807\n",
      "[2,  5800] loss: 0.892\n",
      "[2,  6000] loss: 0.638\n",
      "[2,  6200] loss: 0.425\n",
      "[2,  6400] loss: 0.425\n",
      "[2,  6600] loss: 0.921\n",
      "[2,  6800] loss: 0.889\n",
      "[2,  7000] loss: 0.565\n",
      "[2,  7200] loss: 0.425\n",
      "[2,  7400] loss: 0.655\n",
      "[2,  7600] loss: 0.912\n",
      "[2,  7800] loss: 0.829\n",
      "[2,  8000] loss: 0.425\n",
      "[2,  8200] loss: 0.472\n",
      "[2,  8400] loss: 0.921\n",
      "[2,  8600] loss: 0.931\n",
      "[2,  8800] loss: 0.495\n",
      "[2,  9000] loss: 0.425\n",
      "[2,  9200] loss: 0.638\n",
      "[2,  9400] loss: 0.912\n",
      "[2,  9600] loss: 0.778\n",
      "[2,  9800] loss: 0.425\n",
      "[2, 10000] loss: 0.395\n",
      "[2, 10200] loss: 0.927\n",
      "[2, 10400] loss: 0.912\n",
      "[2, 10600] loss: 0.527\n",
      "[2, 10800] loss: 0.425\n",
      "[2, 11000] loss: 0.664\n",
      "[2, 11200] loss: 0.870\n",
      "[2, 11400] loss: 0.749\n",
      "[2, 11600] loss: 0.425\n",
      "[2, 11800] loss: 0.416\n",
      "[2, 12000] loss: 0.940\n",
      "[2, 12200] loss: 0.918\n",
      "[2, 12400] loss: 0.523\n",
      "[2, 12600] loss: 0.425\n",
      "[2, 12800] loss: 0.639\n",
      "[2, 13000] loss: 0.899\n",
      "[2, 13200] loss: 0.819\n",
      "[2, 13400] loss: 0.425\n",
      "[2, 13600] loss: 0.425\n",
      "[2, 13800] loss: 0.921\n",
      "[2, 14000] loss: 0.988\n",
      "[2, 14200] loss: 0.609\n",
      "[2, 14400] loss: 0.425\n",
      "[2, 14600] loss: 0.654\n",
      "[2, 14800] loss: 0.892\n",
      "[2, 15000] loss: 0.819\n",
      "[2, 15200] loss: 0.425\n",
      "[2, 15400] loss: 0.423\n",
      "[2, 15600] loss: 0.921\n",
      "[2, 15800] loss: 0.902\n",
      "[2, 16000] loss: 0.590\n",
      "[2, 16200] loss: 0.425\n",
      "[2, 16400] loss: 0.584\n",
      "[2, 16600] loss: 0.854\n",
      "[2, 16800] loss: 0.857\n",
      "[2, 17000] loss: 0.425\n",
      "[2, 17200] loss: 0.414\n",
      "[2, 17400] loss: 0.889\n",
      "[2, 17600] loss: 0.969\n",
      "[2, 17800] loss: 0.619\n",
      "[2, 18000] loss: 0.425\n",
      "[2, 18200] loss: 0.624\n",
      "[2, 18400] loss: 0.924\n",
      "[2, 18600] loss: 0.857\n",
      "[2, 18800] loss: 0.425\n",
      "[2, 19000] loss: 0.520\n",
      "[2, 19200] loss: 0.886\n",
      "[2, 19400] loss: 0.985\n",
      "[2, 19600] loss: 0.472\n",
      "[2, 19800] loss: 0.425\n",
      "[2, 20000] loss: 0.555\n",
      "[2, 20200] loss: 0.886\n",
      "[2, 20400] loss: 0.886\n",
      "[2, 20600] loss: 0.431\n",
      "[2, 20800] loss: 0.418\n",
      "[2, 21000] loss: 0.657\n",
      "[2, 21200] loss: 0.466\n",
      "[2, 21400] loss: 0.425\n",
      "[2, 21600] loss: 0.425\n",
      "Accuracy of the network on the 1810 test images: 62 %\n",
      "[3,   200] loss: 0.653\n",
      "[3,   400] loss: 0.755\n",
      "[3,   600] loss: 0.738\n",
      "[3,   800] loss: 0.545\n",
      "[3,  1000] loss: 0.545\n",
      "[3,  1200] loss: 0.801\n",
      "[3,  1400] loss: 0.788\n",
      "[3,  1600] loss: 0.569\n",
      "[3,  1800] loss: 0.545\n",
      "[3,  2000] loss: 0.621\n",
      "[3,  2200] loss: 0.751\n",
      "[3,  2400] loss: 0.772\n",
      "[3,  2600] loss: 0.545\n",
      "[3,  2800] loss: 0.545\n",
      "[3,  3000] loss: 0.766\n",
      "[3,  3200] loss: 0.793\n",
      "[3,  3400] loss: 0.651\n",
      "[3,  3600] loss: 0.545\n",
      "[3,  3800] loss: 0.634\n",
      "[3,  4000] loss: 0.776\n",
      "[3,  4200] loss: 0.763\n",
      "[3,  4400] loss: 0.546\n",
      "[3,  4600] loss: 0.545\n",
      "[3,  4800] loss: 0.774\n",
      "[3,  5000] loss: 0.814\n",
      "[3,  5200] loss: 0.651\n",
      "[3,  5400] loss: 0.545\n",
      "[3,  5600] loss: 0.738\n",
      "[3,  5800] loss: 0.782\n",
      "[3,  6000] loss: 0.653\n",
      "[3,  6200] loss: 0.545\n",
      "[3,  6400] loss: 0.545\n",
      "[3,  6600] loss: 0.797\n",
      "[3,  6800] loss: 0.780\n",
      "[3,  7000] loss: 0.616\n",
      "[3,  7200] loss: 0.545\n",
      "[3,  7400] loss: 0.655\n",
      "[3,  7600] loss: 0.792\n",
      "[3,  7800] loss: 0.750\n",
      "[3,  8000] loss: 0.545\n",
      "[3,  8200] loss: 0.569\n",
      "[3,  8400] loss: 0.797\n",
      "[3,  8600] loss: 0.801\n",
      "[3,  8800] loss: 0.580\n",
      "[3,  9000] loss: 0.545\n",
      "[3,  9200] loss: 0.653\n",
      "[3,  9400] loss: 0.792\n",
      "[3,  9600] loss: 0.724\n",
      "[3,  9800] loss: 0.545\n",
      "[3, 10000] loss: 0.507\n",
      "[3, 10200] loss: 0.800\n",
      "[3, 10400] loss: 0.792\n",
      "[3, 10600] loss: 0.596\n",
      "[3, 10800] loss: 0.545\n",
      "[3, 11000] loss: 0.660\n",
      "[3, 11200] loss: 0.771\n",
      "[3, 11400] loss: 0.709\n",
      "[3, 11600] loss: 0.545\n",
      "[3, 11800] loss: 0.534\n",
      "[3, 12000] loss: 0.806\n",
      "[3, 12200] loss: 0.795\n",
      "[3, 12400] loss: 0.595\n",
      "[3, 12600] loss: 0.545\n",
      "[3, 12800] loss: 0.652\n",
      "[3, 13000] loss: 0.785\n",
      "[3, 13200] loss: 0.745\n",
      "[3, 13400] loss: 0.545\n",
      "[3, 13600] loss: 0.545\n",
      "[3, 13800] loss: 0.797\n",
      "[3, 14000] loss: 0.830\n",
      "[3, 14200] loss: 0.638\n",
      "[3, 14400] loss: 0.545\n",
      "[3, 14600] loss: 0.661\n",
      "[3, 14800] loss: 0.782\n",
      "[3, 15000] loss: 0.745\n",
      "[3, 15200] loss: 0.545\n",
      "[3, 15400] loss: 0.542\n",
      "[3, 15600] loss: 0.797\n",
      "[3, 15800] loss: 0.787\n",
      "[3, 16000] loss: 0.629\n",
      "[3, 16200] loss: 0.545\n",
      "[3, 16400] loss: 0.606\n",
      "[3, 16600] loss: 0.763\n",
      "[3, 16800] loss: 0.764\n",
      "[3, 17000] loss: 0.545\n",
      "[3, 17200] loss: 0.531\n",
      "[3, 17400] loss: 0.780\n",
      "[3, 17600] loss: 0.821\n",
      "[3, 17800] loss: 0.643\n",
      "[3, 18000] loss: 0.545\n",
      "[3, 18200] loss: 0.638\n",
      "[3, 18400] loss: 0.798\n",
      "[3, 18600] loss: 0.764\n",
      "[3, 18800] loss: 0.545\n",
      "[3, 19000] loss: 0.593\n",
      "[3, 19200] loss: 0.779\n",
      "[3, 19400] loss: 0.829\n",
      "[3, 19600] loss: 0.569\n",
      "[3, 19800] loss: 0.545\n",
      "[3, 20000] loss: 0.611\n",
      "[3, 20200] loss: 0.779\n",
      "[3, 20400] loss: 0.779\n",
      "[3, 20600] loss: 0.548\n",
      "[3, 20800] loss: 0.537\n",
      "[3, 21000] loss: 0.663\n",
      "[3, 21200] loss: 0.566\n",
      "[3, 21400] loss: 0.545\n",
      "[3, 21600] loss: 0.545\n",
      "Accuracy of the network on the 1810 test images: 62 %\n",
      "[4,   200] loss: 0.643\n",
      "[4,   400] loss: 0.927\n",
      "[4,   600] loss: 0.882\n",
      "[4,   800] loss: 0.340\n",
      "[4,  1000] loss: 0.340\n",
      "[4,  1200] loss: 1.058\n",
      "[4,  1400] loss: 1.022\n",
      "[4,  1600] loss: 0.408\n",
      "[4,  1800] loss: 0.340\n",
      "[4,  2000] loss: 0.552\n",
      "[4,  2200] loss: 0.918\n",
      "[4,  2400] loss: 0.977\n",
      "[4,  2600] loss: 0.340\n",
      "[4,  2800] loss: 0.340\n",
      "[4,  3000] loss: 0.959\n",
      "[4,  3200] loss: 1.036\n",
      "[4,  3400] loss: 0.638\n",
      "[4,  3600] loss: 0.340\n",
      "[4,  3800] loss: 0.596\n",
      "[4,  4000] loss: 0.986\n",
      "[4,  4200] loss: 0.950\n",
      "[4,  4400] loss: 0.345\n",
      "[4,  4600] loss: 0.340\n",
      "[4,  4800] loss: 0.981\n",
      "[4,  5000] loss: 1.094\n",
      "[4,  5200] loss: 0.638\n",
      "[4,  5400] loss: 0.340\n",
      "[4,  5600] loss: 0.882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  5800] loss: 1.004\n",
      "[4,  6000] loss: 0.643\n",
      "[4,  6200] loss: 0.340\n",
      "[4,  6400] loss: 0.340\n",
      "[4,  6600] loss: 1.045\n",
      "[4,  6800] loss: 1.000\n",
      "[4,  7000] loss: 0.539\n",
      "[4,  7200] loss: 0.340\n",
      "[4,  7400] loss: 0.672\n",
      "[4,  7600] loss: 1.031\n",
      "[4,  7800] loss: 0.914\n",
      "[4,  8000] loss: 0.340\n",
      "[4,  8200] loss: 0.408\n",
      "[4,  8400] loss: 1.045\n",
      "[4,  8600] loss: 1.058\n",
      "[4,  8800] loss: 0.440\n",
      "[4,  9000] loss: 0.340\n",
      "[4,  9200] loss: 0.643\n",
      "[4,  9400] loss: 1.031\n",
      "[4,  9600] loss: 0.841\n",
      "[4,  9800] loss: 0.340\n",
      "[4, 10000] loss: 0.316\n",
      "[4, 10200] loss: 1.054\n",
      "[4, 10400] loss: 1.031\n",
      "[4, 10600] loss: 0.485\n",
      "[4, 10800] loss: 0.340\n",
      "[4, 11000] loss: 0.686\n",
      "[4, 11200] loss: 0.972\n",
      "[4, 11400] loss: 0.801\n",
      "[4, 11600] loss: 0.340\n",
      "[4, 11800] loss: 0.333\n",
      "[4, 12000] loss: 1.072\n",
      "[4, 12200] loss: 1.040\n",
      "[4, 12400] loss: 0.480\n",
      "[4, 12600] loss: 0.340\n",
      "[4, 12800] loss: 0.646\n",
      "[4, 13000] loss: 1.013\n",
      "[4, 13200] loss: 0.900\n",
      "[4, 13400] loss: 0.340\n",
      "[4, 13600] loss: 0.340\n",
      "[4, 13800] loss: 1.045\n",
      "[4, 14000] loss: 1.140\n",
      "[4, 14200] loss: 0.602\n",
      "[4, 14400] loss: 0.340\n",
      "[4, 14600] loss: 0.665\n",
      "[4, 14800] loss: 1.004\n",
      "[4, 15000] loss: 0.900\n",
      "[4, 15200] loss: 0.340\n",
      "[4, 15400] loss: 0.339\n",
      "[4, 15600] loss: 1.045\n",
      "[4, 15800] loss: 1.018\n",
      "[4, 16000] loss: 0.575\n",
      "[4, 16200] loss: 0.340\n",
      "[4, 16400] loss: 0.582\n",
      "[4, 16600] loss: 0.950\n",
      "[4, 16800] loss: 0.954\n",
      "[4, 17000] loss: 0.340\n",
      "[4, 17200] loss: 0.332\n",
      "[4, 17400] loss: 1.000\n",
      "[4, 17600] loss: 1.112\n",
      "[4, 17800] loss: 0.616\n",
      "[4, 18000] loss: 0.340\n",
      "[4, 18200] loss: 0.630\n",
      "[4, 18400] loss: 1.049\n",
      "[4, 18600] loss: 0.954\n",
      "[4, 18800] loss: 0.340\n",
      "[4, 19000] loss: 0.476\n",
      "[4, 19200] loss: 0.995\n",
      "[4, 19400] loss: 1.135\n",
      "[4, 19600] loss: 0.408\n",
      "[4, 19800] loss: 0.340\n",
      "[4, 20000] loss: 0.525\n",
      "[4, 20200] loss: 0.995\n",
      "[4, 20400] loss: 0.995\n",
      "[4, 20600] loss: 0.349\n",
      "[4, 20800] loss: 0.335\n",
      "[4, 21000] loss: 0.670\n",
      "[4, 21200] loss: 0.399\n",
      "[4, 21400] loss: 0.340\n",
      "[4, 21600] loss: 0.340\n",
      "Accuracy of the network on the 1810 test images: 62 %\n",
      "[5,   200] loss: 0.640\n",
      "[5,   400] loss: 0.815\n",
      "[5,   600] loss: 0.787\n",
      "[5,   800] loss: 0.453\n",
      "[5,  1000] loss: 0.453\n",
      "[5,  1200] loss: 0.896\n",
      "[5,  1400] loss: 0.874\n",
      "[5,  1600] loss: 0.494\n",
      "[5,  1800] loss: 0.453\n",
      "[5,  2000] loss: 0.584\n",
      "[5,  2200] loss: 0.810\n",
      "[5,  2400] loss: 0.846\n",
      "[5,  2600] loss: 0.453\n",
      "[5,  2800] loss: 0.453\n",
      "[5,  3000] loss: 0.835\n",
      "[5,  3200] loss: 0.882\n",
      "[5,  3400] loss: 0.637\n",
      "[5,  3600] loss: 0.453\n",
      "[5,  3800] loss: 0.609\n",
      "[5,  4000] loss: 0.852\n",
      "[5,  4200] loss: 0.829\n",
      "[5,  4400] loss: 0.455\n",
      "[5,  4600] loss: 0.453\n",
      "[5,  4800] loss: 0.849\n",
      "[5,  5000] loss: 0.919\n",
      "[5,  5200] loss: 0.637\n",
      "[5,  5400] loss: 0.453\n",
      "[5,  5600] loss: 0.787\n",
      "[5,  5800] loss: 0.863\n",
      "[5,  6000] loss: 0.640\n",
      "[5,  6200] loss: 0.453\n",
      "[5,  6400] loss: 0.453\n",
      "[5,  6600] loss: 0.888\n",
      "[5,  6800] loss: 0.860\n",
      "[5,  7000] loss: 0.575\n",
      "[5,  7200] loss: 0.453\n",
      "[5,  7400] loss: 0.653\n",
      "[5,  7600] loss: 0.879\n",
      "[5,  7800] loss: 0.807\n",
      "[5,  8000] loss: 0.453\n",
      "[5,  8200] loss: 0.494\n",
      "[5,  8400] loss: 0.888\n",
      "[5,  8600] loss: 0.896\n",
      "[5,  8800] loss: 0.514\n",
      "[5,  9000] loss: 0.453\n",
      "[5,  9200] loss: 0.640\n",
      "[5,  9400] loss: 0.879\n",
      "[5,  9600] loss: 0.762\n",
      "[5,  9800] loss: 0.453\n",
      "[5, 10000] loss: 0.421\n",
      "[5, 10200] loss: 0.893\n",
      "[5, 10400] loss: 0.879\n",
      "[5, 10600] loss: 0.542\n",
      "[5, 10800] loss: 0.453\n",
      "[5, 11000] loss: 0.661\n",
      "[5, 11200] loss: 0.843\n",
      "[5, 11400] loss: 0.737\n",
      "[5, 11600] loss: 0.453\n",
      "[5, 11800] loss: 0.443\n",
      "[5, 12000] loss: 0.905\n",
      "[5, 12200] loss: 0.885\n",
      "[5, 12400] loss: 0.539\n",
      "[5, 12600] loss: 0.453\n",
      "[5, 12800] loss: 0.640\n",
      "[5, 13000] loss: 0.868\n",
      "[5, 13200] loss: 0.799\n",
      "[5, 13400] loss: 0.453\n",
      "[5, 13600] loss: 0.453\n",
      "[5, 13800] loss: 0.888\n",
      "[5, 14000] loss: 0.946\n",
      "[5, 14200] loss: 0.614\n",
      "[5, 14400] loss: 0.453\n",
      "[5, 14600] loss: 0.653\n",
      "[5, 14800] loss: 0.863\n",
      "[5, 15000] loss: 0.799\n",
      "[5, 15200] loss: 0.453\n",
      "[5, 15400] loss: 0.450\n",
      "[5, 15600] loss: 0.888\n",
      "[5, 15800] loss: 0.871\n",
      "[5, 16000] loss: 0.598\n",
      "[5, 16200] loss: 0.453\n",
      "[5, 16400] loss: 0.587\n",
      "[5, 16600] loss: 0.829\n",
      "[5, 16800] loss: 0.832\n",
      "[5, 17000] loss: 0.453\n",
      "[5, 17200] loss: 0.441\n",
      "[5, 17400] loss: 0.860\n",
      "[5, 17600] loss: 0.930\n",
      "[5, 17800] loss: 0.623\n",
      "[5, 18000] loss: 0.453\n",
      "[5, 18200] loss: 0.625\n",
      "[5, 18400] loss: 0.891\n",
      "[5, 18600] loss: 0.832\n",
      "[5, 18800] loss: 0.453\n",
      "[5, 19000] loss: 0.536\n",
      "[5, 19200] loss: 0.857\n",
      "[5, 19400] loss: 0.944\n",
      "[5, 19600] loss: 0.494\n",
      "[5, 19800] loss: 0.453\n",
      "[5, 20000] loss: 0.567\n",
      "[5, 20200] loss: 0.857\n",
      "[5, 20400] loss: 0.857\n",
      "[5, 20600] loss: 0.458\n",
      "[5, 20800] loss: 0.446\n",
      "[5, 21000] loss: 0.656\n",
      "[5, 21200] loss: 0.489\n",
      "[5, 21400] loss: 0.453\n",
      "[5, 21600] loss: 0.453\n",
      "Accuracy of the network on the 1810 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "# Training Phase\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    train_function(trainloader, net, optimizer, criterion)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels_var = Variable(inputs.unsqueeze(0).float(), volatile=True), Variable(labels.long(), volatile=True)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels_var)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "#         print ('predicted: %d' % (predicted))\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the network on the 1810 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10, 10])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2920 -0.2586\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4865  0.5135\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input to CNN is 10x10\n",
    "\n",
    "input = Variable(torch.randn(1, 1, 10, 10)) # Here random input is given\n",
    "out = net(input)\n",
    "print(out)\n",
    "# output size is 1x2 because there are 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10853, 2)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get test data\n",
    "'''\n",
    "test_data = pickle.load(open('test_data.pkl','r'))\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data #Test on first 2000 image segments\n",
    "\n",
    "X_Test = test_data[:,0]\n",
    "y_Test = test_data[:,1]\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DUMMY CODE\n",
    "# out = net(input)\n",
    "target = Variable(torch.arange(0, 2))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "N = len(X_Train)\n",
    "H = X_Train[0].shape[0]\n",
    "W = X_Train[0].shape[1]\n",
    "trainTensor = torch.LongTensor(N, H, W)\n",
    "for i in range(N):\n",
    "    trainTensor[i] = torch.LongTensor(X_Train[i].tolist())\n",
    "trainTensor = trainTensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109, 106, 105, 100,  98,  98,  98,  94,  95,  90],\n",
       "       [ 38,  48,  44,  32,  38,  35,  36,  29,  33,  29],\n",
       "       [ 24,  22,  24,  24,  21,  22,  22,  20,  19,  21],\n",
       "       [  8,   8,   7,   8,  10,  10,   8,   8,   9,   8],\n",
       "       [ 23,  21,  21,   8,  19,   3,  24,  30,  26,  22],\n",
       "       [  7,   7,   5,   4,   7,   9,   8,   7,   6,   7],\n",
       "       [  1,   0,   0,   0,   1,   7,   2,   2,   3,   1],\n",
       "       [ 13,   7,   3,   4,   2,   7,  11,   4,   9,   9],\n",
       "       [ 18,  23,  36,  18,  28,  28,  37,  47,  39,  50],\n",
       "       [ 24,  35,  31,  51,  10,  55,  66,  77,  67,  61]], dtype=uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  109  106  105  100   98   98   98   94   95   90\n",
       "   38   48   44   32   38   35   36   29   33   29\n",
       "   24   22   24   24   21   22   22   20   19   21\n",
       "    8    8    7    8   10   10    8    8    9    8\n",
       "   23   21   21    8   19    3   24   30   26   22\n",
       "    7    7    5    4    7    9    8    7    6    7\n",
       "    1    0    0    0    1    7    2    2    3    1\n",
       "   13    7    3    4    2    7   11    4    9    9\n",
       "   18   23   36   18   28   28   37   47   39   50\n",
       "   24   35   31   51   10   55   66   77   67   61\n",
       "[torch.ByteTensor of size 1x10x10]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  244  247  238  233  232  218  229  228  214  231\n",
       "  229  239  245  212  216  228  212  216  210  222\n",
       "  226  225  233  219  236  222  233  235  234  229\n",
       "  238  233  242  232  235  227  233  229  230  232\n",
       "  240  237  226  229  226  234  208  234  218  231\n",
       "  231  226  232  231  214  219  228  238  223  217\n",
       "  191  212  191  226  214  159  186  220  211  213\n",
       "  236  232  227  226  217  185  223  208  216  208\n",
       "  229  224  228  233  227  219  226  208  217  208\n",
       "  221  230  217  221  232  225  232  220  202  215\n",
       "[torch.FloatTensor of size 1x1x10x10]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.arange(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_t= Variable(torch.randn(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.4050 -0.0642  0.6156 -1.4410  0.9281\n",
       "-0.1144 -0.0128  2.6492 -1.2253 -1.1597\n",
       " 0.5336  2.3839  1.5902 -1.5398  0.1211\n",
       "[torch.FloatTensor of size 3x5]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_t = Variable(torch.LongTensor(3).random_(5))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 0\n",
       " 2\n",
       "[torch.LongTensor of size 3]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-76ffd58e8774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/poorvarane/anaconda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36munsqueeze\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mUnsqueeze\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/poorvarane/anaconda/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, dim)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "labels.unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
