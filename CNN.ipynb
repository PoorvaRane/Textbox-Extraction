{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The architecture of our CNN is given in Figure 1. The structure\n",
    "# can be summarized as 28×28×1−26×26×4−100−M,\n",
    "# where M is the number of classes. The input is a grayscale\n",
    "# image patch. The size of the image patch is 28×28 pixels. Our\n",
    "# CNN architecture contains only one convolution layer which\n",
    "# consists of 4 kernels. The size of each kernel is 3 × 3 pixels.\n",
    "# Unlike other traditional CNN architecture, the pooling layer is\n",
    "# not used in our architecture. Then one fully connected layer\n",
    "# of 100 neurons follows the convolution layer. The last layer\n",
    "# consists of a logistic regression with softmax which outputs\n",
    "# the probability of each class, such that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get train data\n",
    "'''\n",
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "training_data = training_data[:6000] #Test on first 2000 image segments\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self): # DO NOT HARDCODE\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel 10x10, 4 output channels, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 4, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(4 * 8 * 8, 100)\n",
    "        self.fc2 = nn.Linear(100, 2) #Number of classes = 'text'\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear (256 -> 100)\n",
      "  (fc2): Linear (100 -> 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([4, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Total number of learnable parameters\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "trainloader = DataLoader(training_data.tolist(), batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.698\n",
      "[1,   400] loss: 0.683\n",
      "[1,   600] loss: 0.713\n",
      "[1,   800] loss: 0.678\n",
      "[1,  1000] loss: 0.688\n",
      "[1,  1200] loss: 0.668\n",
      "[1,  1400] loss: 0.688\n",
      "[1,  1600] loss: 0.678\n",
      "[1,  1800] loss: 0.653\n",
      "[1,  2000] loss: 0.738\n",
      "[1,  2200] loss: 0.698\n",
      "[1,  2400] loss: 0.748\n",
      "[1,  2600] loss: 0.713\n",
      "[1,  2800] loss: 0.793\n",
      "[1,  3000] loss: 0.683\n",
      "[1,  3200] loss: 0.638\n",
      "[1,  3400] loss: 0.678\n",
      "[1,  3600] loss: 0.758\n",
      "[1,  3800] loss: 0.698\n",
      "[1,  4000] loss: 0.713\n",
      "[1,  4200] loss: 0.693\n",
      "[1,  4400] loss: 0.738\n",
      "[1,  4600] loss: 0.698\n",
      "[1,  4800] loss: 0.763\n",
      "[1,  5000] loss: 0.728\n",
      "[1,  5200] loss: 0.753\n",
      "[1,  5400] loss: 0.753\n",
      "[1,  5600] loss: 0.718\n",
      "[1,  5800] loss: 0.683\n",
      "[1,  6000] loss: 0.658\n",
      "[2,   200] loss: 0.693\n",
      "[2,   400] loss: 0.718\n",
      "[2,   600] loss: 0.743\n",
      "[2,   800] loss: 0.738\n",
      "[2,  1000] loss: 0.663\n",
      "[2,  1200] loss: 0.678\n",
      "[2,  1400] loss: 0.738\n",
      "[2,  1600] loss: 0.723\n",
      "[2,  1800] loss: 0.673\n",
      "[2,  2000] loss: 0.668\n",
      "[2,  2200] loss: 0.688\n",
      "[2,  2400] loss: 0.733\n",
      "[2,  2600] loss: 0.693\n",
      "[2,  2800] loss: 0.653\n",
      "[2,  3000] loss: 0.728\n",
      "[2,  3200] loss: 0.733\n",
      "[2,  3400] loss: 0.748\n",
      "[2,  3600] loss: 0.703\n",
      "[2,  3800] loss: 0.693\n",
      "[2,  4000] loss: 0.693\n",
      "[2,  4200] loss: 0.713\n",
      "[2,  4400] loss: 0.758\n",
      "[2,  4600] loss: 0.708\n",
      "[2,  4800] loss: 0.698\n",
      "[2,  5000] loss: 0.698\n",
      "[2,  5200] loss: 0.768\n",
      "[2,  5400] loss: 0.698\n",
      "[2,  5600] loss: 0.723\n",
      "[2,  5800] loss: 0.693\n",
      "[2,  6000] loss: 0.633\n"
     ]
    }
   ],
   "source": [
    "# Training Phase\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.unsqueeze(1).float()), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.4865  0.5135\n",
      "[torch.FloatTensor of size 1x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input to CNN is 10x10\n",
    "\n",
    "input = Variable(torch.randn(1, 1, 10, 10)) # Here random input is given\n",
    "out = net(input)\n",
    "print(out)\n",
    "# output size is 1x2 because there are 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero the gradient buffers of all parameters and backprops with random gradients\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DUMMY CODE\n",
    "# out = net(input)\n",
    "target = Variable(torch.arange(0, 2))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pickle.load(open('training_data.pkl','r'))\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "\n",
    "X_Train = training_data[:,0]\n",
    "y_Train = training_data[:,1]\n",
    "\n",
    "N = len(X_Train)\n",
    "H = X_Train[0].shape[0]\n",
    "W = X_Train[0].shape[1]\n",
    "trainTensor = torch.LongTensor(N, H, W)\n",
    "for i in range(N):\n",
    "    trainTensor[i] = torch.LongTensor(X_Train[i].tolist())\n",
    "trainTensor = trainTensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109, 106, 105, 100,  98,  98,  98,  94,  95,  90],\n",
       "       [ 38,  48,  44,  32,  38,  35,  36,  29,  33,  29],\n",
       "       [ 24,  22,  24,  24,  21,  22,  22,  20,  19,  21],\n",
       "       [  8,   8,   7,   8,  10,  10,   8,   8,   9,   8],\n",
       "       [ 23,  21,  21,   8,  19,   3,  24,  30,  26,  22],\n",
       "       [  7,   7,   5,   4,   7,   9,   8,   7,   6,   7],\n",
       "       [  1,   0,   0,   0,   1,   7,   2,   2,   3,   1],\n",
       "       [ 13,   7,   3,   4,   2,   7,  11,   4,   9,   9],\n",
       "       [ 18,  23,  36,  18,  28,  28,  37,  47,  39,  50],\n",
       "       [ 24,  35,  31,  51,  10,  55,  66,  77,  67,  61]], dtype=uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  109  106  105  100   98   98   98   94   95   90\n",
       "   38   48   44   32   38   35   36   29   33   29\n",
       "   24   22   24   24   21   22   22   20   19   21\n",
       "    8    8    7    8   10   10    8    8    9    8\n",
       "   23   21   21    8   19    3   24   30   26   22\n",
       "    7    7    5    4    7    9    8    7    6    7\n",
       "    1    0    0    0    1    7    2    2    3    1\n",
       "   13    7    3    4    2    7   11    4    9    9\n",
       "   18   23   36   18   28   28   37   47   39   50\n",
       "   24   35   31   51   10   55   66   77   67   61\n",
       "[torch.ByteTensor of size 1x10x10]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, label = dataiter.next()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  244  247  238  233  232  218  229  228  214  231\n",
       "  229  239  245  212  216  228  212  216  210  222\n",
       "  226  225  233  219  236  222  233  235  234  229\n",
       "  238  233  242  232  235  227  233  229  230  232\n",
       "  240  237  226  229  226  234  208  234  218  231\n",
       "  231  226  232  231  214  219  228  238  223  217\n",
       "  191  212  191  226  214  159  186  220  211  213\n",
       "  236  232  227  226  217  185  223  208  216  208\n",
       "  229  224  228  233  227  219  226  208  217  208\n",
       "  221  230  217  221  232  225  232  220  202  215\n",
       "[torch.FloatTensor of size 1x1x10x10]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.arange(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
